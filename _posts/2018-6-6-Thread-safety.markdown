---
layout:    post
title:    "Java 多线程的一点学习记录"
subtitle:    "introduction to Java multiple thread"
date:    2018-06-06 18:00:00
catalog:    true
tags:
    - java
    - 学习记录
---

#### **1、关于并行 (concurrent)**

##### **1.1、什么是并行 (concurrent)？**

并行在现代的计算机中十分常见，简单的说就是在同一个时间进行着不同的任
务。举几个简单的例子:
* 不同的计算机进行任务时是并行的；
* 一台计算机会同时运行着的多个应用是并行的；
* 一个CPU上的多个核心处理任务是并行的；
* Web 服务器对每个用户的响应也是并行的；
* 一个 app 在本地和在云端的计算是并行的；
* 一个 app 前端 GUI 的显示和后端数据的处理也是并行的；

##### **1.2、为什么要并行 (concurrent)？**

为什么要并行？我觉得是一个答案明显的问题，只需要关注两个方面：一是我
们需要；二是我们能。当然，关于我们能这个问题也没啥好说的，一般而言只
要愿意，总是有办法能做到的。所以主要原因就是我们需要。举几个例子:
* 我们一直努力提升计算机的计算能力，但是一段时间后摩尔定律失效，计算机的时钟频率达到一个瓶颈。而使用并行的方式可以在不突破这个瓶颈下，提供近似摩尔定律的性能提升。
* 现在使用计算机的方式发生了很大的变化，计算机不在只是用来简单进行科学计算，现在计算机更多的用作生活的工具，我们希望在敲代码的时候能听个轻松的音乐。

##### **1.3、并行的实现形式**

要实现并行的计算，我们必须依赖于一定的机制。现在，我们关于并行的策略，大体上有三种：

第一种最简单最原始，那就是不同的计算机之间天然构成并行的环境。在每台计算机只能同时做一件事情的时候，完全可以用多台计算机来达到边听音乐边敲代码的目的。

第二种方式就是依赖于进程。简单的说，如果将一台计算机看作是一座大楼，那么进程就像是一楼大楼里的一层楼，每层楼都可以做自己的事情。它有一些特点：
* 计算机的每个进程都是相互独立的，它们拥有整台计算机的资源；
* 一般而言，一个进程也就意味着一个应用；
* 进程为应用提供一个拥有整台计算机的假设，但实际上一台计算机可以拥有多个进程，这样每台计算机就可以在同一个时间运行多个应用；
* 进程拥有整台计算机的资源，但是它实际上又没有整台计算机的资源。进程相当于是计算机资源的一个动态调整大小的子集；
* 多个进程之间通过消息传递的方式进行协作，可以是同一台计算机内的进程，也可以是不同计算机内的进程；
* 主线程负责回收自己创建的子线程，若是主线程先于子线程结束，则子线程会成为一个特定线程（叫做 init 的线程）的子线程；

第三种方式就是线程。类似于进程，一个线程也是一个较为独立的整体，但是线程的独立性次于进程：
* 线程从属于进程，占用一个进程的资源；
* 一个进程拥有至少一个线程；
* 同一个进程的线程间拥有较高的关联性，它们不仅可以通过消息传递的方式进行协作，它们本身也可以共享同一段内存；
* 主线程可以创建子线程，但是事实上线程并没有那么明显的主次之分，主线程更多的意义是进程的入口线程；

总体来看，第一种方式并没有什么讨论的价值；进程相比于线程拥有更高的独立性，但是它的调度是操作系统的事情，开发应用的程序员对此也束手无策；唯一值得讨论的就是线程了。

#### **2、线程的不安全性**
进程拥有很高的独立性，因此并不用担心进程之间的相互干扰造成不安全。而线程之间就不一样了，线程之间通过共享内存连续紧密，容易因为多个线程对同一段内存的读写，引发程序的安全隐患。

##### **2.1、启动一个新线程**

一个线程，必须要有执行的任务才有意义，就像一个进程（实际上就是主线程）需要一个入口，要创建一个新的线程，要依托于一个类来提供入口，这个函数里面必须要实现一个`run()`方法。要实现这个方法，有三种方式，这里我们只关注其中最常用的一种方式：实现`Runable`接口。下面是一个例子：
{% highlight java %}
public class Test implements Runnable {
	
	// 在这个方法相当于主线程中的 main 方法
	@Override
	public void run() {
		System.out.println("test");
	}

	public static void main(String[] args) {
		Thread thread = new Thread(new Test());
		thread.start();
	}
}
{% endhighlight %}

除此，还有两种方式可以创建一个新的线程，它们的区别在于提供入口方法时的细节。实际上，无论是哪一种方式，“创建并启动一个新的线程”这件事情都是调用`Thread`类的`start()`方法实现的。

##### **2.2、交错和竞争 (Interleaving and Race Condition)**

###### **2.2.1、时间分片 (Time slicing)**

对于同一台计算机上运行的线程、甚至是进程来说，它们不可能真正的独享整台计算机的资源，就算是只占用 CPU 的每个核也不行。因为在一台计算机上运行的线程和进程的数量是多于 CPU 核心的数量的。要计算机在同一个时间执行这么多进程实际上是不可能的。但是操作系统通过时间切片的方式来造成每个进程和线程都独占资源的假象。

以一个 CPU 核心为例，一个时间里 CUP只能处理一个计算任务，在一段连续的时间里 CPU 可以处理一系列的任务。操作系统将 CPU 的是时间划分为若干片段，每个片段可以分给不同的线程。就像我们可以将一天的时间分成上午和下午，然后上午出去玩儿，而下午在教室里好好学习。这样，每个线程就像是在同一时间进行了。具体情况如下图所示：
![time slicing 的示意图](/img/post/time-slicing.png)
实线就表示当前进程正在执行当中。**这个过程是由操作系统完成的，程序员是无能为力的。**

这样看来，多个进程的“并行”的实际行为是各个线程交错执行，它们具体的顺序是难以预测的。这对于多进程间通常是没什么影响的，因为进程间几乎就是独立的。但是多线程之间的联系较为紧密，这样的不可控的交错可能造成十分隐晦的安全隐患。

###### **2.2.2、线程不安全的来源：共享内存 (Shared Memory among Threads)**

如果多个线程共享某一段内存，或者更具体的说，共享某一个数据结构，并且每一个线程对这个数据结构都拥有读写的权限，那么线程间执行的顺序的不确定性就可能造成意想不到的危险。下面看一个例子：
{% highlight java %}
// 代表一个银行账户
public class Account {

	// 存储账户余额
	private int balance = 0;
	
	// 存入一美元
	public void deposit() {
		balance = balance + 1;
	}
	
	// 取出一美元
	public void withdraw() {
		balance = balance - 1;
	}
}
{% endhighlight %}
现在有必要对标题中的“交错和竞争”做一个解释：
* **交错**：就是指多个线程交错执行的过程；
* **竞争**：就是指多个线程对同一个数据结构的读写是在交错的过程中；

看上面这个例子，假设有两个 ATM（分别叫做A、B），同时对同一个账户进行操作。也就是说，两个线程共享一个数据结构。但是，上面的代码显得有点短，为了描述的准确，我们可以将一个`deposit()`操作分解成较为底层的指令：
{% highlight cmd %}
get balance
add 1
write back the result
{% endhighlight %}
那么这样在两个线程同时对这个数据结构进行`deposit()`操作时，会出现包括但不限于下列两种情况：
![A、B 线程同时操作 deposit 的两种可能情形](/img/post/two-threads-deposit.png)
第一种情况中两个线程实际上是串行执行的，所以没有问题。

第二种情况中，两个线程交错执行，B 在 A 还没有将结果写回时，就读取了`balance`的值，这样造成了错误的结果。

#### **3、保障线程安全**

从前面的例子可以看到，线程的安全问题其实就是共享内存，或者说共享数据引发的问题，因此这里解决线程安全问题实际上就是保障数据并发访问的安全性。通常，我们总结了四个策略来保障这一点：
* 不共享数据结构；
* 共享 immutable 类型的数据结构；
* 共享线程安全的数据结构，它可以是 mutable 的；
* 采用 java 提供的 Synchronization 的机制；

前两项策略（尤其是第一项）相当鸡肋，因为多线程间往往是要共享一个 mutable 类型的数据的。而第三项线程安全的 ADT，其实就是其作者作者采用第四项技术得到的，因此我们关注的重点在第四项技术。

##### **3.1、关于 Synchronization 机制的一点理解**

回想一下 2.2.2 中提到的例子，我们可以看到，如果不将代码分解成几行底层的代码，也不会出现那种错误。线程间的交错运行能带来错误的部分，其实就是那些本该“一次性”完成的步骤被分开了。

简单来看，Synchronization 机制就是建立在这种想法上的：它能够让一段连续的代码作为一个“原子”，在执行的时候总是一起执行。如果将一个新线程的入口方法作为一个“原子”，那么这整个方法总是在一个时间分片中执行，这就意味着，这个线程会在同一个时间分片中执行。若是所有线程都使用同样的方式处理，那么效果就是多线程会串行执行。

试想，如果 2.2.2 中提到的例子中，如果三个分解出来的步骤作为一个“原子”的话，就不会发生“修改了值，但还没有写回”的情况。

当然，具体来说，这是一种 java 内嵌的机制，它主要还是用来保护共享的数据结构的。也就是说，Synchronization 机制本质上是在使用共享数据之前先申请将这个数据锁定，而同一时间只能有一个线程锁定同一个数据结构，这样，当其他线程要操作这个数据结构而申请锁时，就会暂时阻塞。在当前线程没有释放这个数据结构的期间，其余的线程的申请会保存在一个队列里等待。这样就达到了前面所有的将一段代码变成“原子”的，实际上这里的“原子”，仅仅是针对操作共享数据结构的时候，有这样的效果（这段“原子”代码的实际执行可能依旧是与其它线程交错的，但是这一段交错的代码里一定只有一个线程在操作共享数据结构）。

这个机制完美解决了对共享数据结构的竞争问题，但是我觉得也有一个小小的缺陷。那就是这个机制依赖于线程的自觉，比如说，一个线程在不申请锁定的情况下，可以随时操作共享数据结构，哪怕有另一个线程拥有这个共享数据结构的锁。

##### **3.2、关于 Synchronization 机制的几个例子**

###### **3.2.1、设计一个线程安全的 ADT**

线程安全的 ADT，基本要求就是同时调用 ADT 的多个操作不能产生竞争。为了实现这个目标，我们可以在每个操作之前都申请将自身锁住，如下：
{% highlight java %}
// 代表一个银行账户
public class Account {

	// 存储账户余额
	private int balance = 0;
	
	// 存入一美元
	public void deposit() {
		synchronized(this) {
			balance = balance + 1;
		}
	}
	
	// 取出一美元
	public void withdraw() {
		synchronized (this) {
			balance = balance - 1;
		}
	}
}
{% endhighlight %}

假设在两个线程 A、B 之间共享上述类的一个实例`account`，当 A 调用`deposit()`方法时，会申请将`account`锁住，若是 B 立马调用`deposit()`方法，那么 B 线程就会因为要申请`account`的锁而不得（A 线程此刻已经拥有它），会被阻塞。效果就是，两个操作会按照严格的串行执行。

当然，并不是说线程安全的 ADT 都必须这样做，实际上，immutable 类型的 ADT 本身就是线程安全的。受此启发：对于 ADT 内部的某一个 rep，若是没有提供修改它的操作，就无需申请对它的锁；相反，若是 ADT 提供了对内部某个 rep 的修改操作，那么在 ADT 的涉及到这个rep的所有操作的开始应该申请对该 rep 的锁，实例如下：
{% highlight java %}
// 代表一个银行账户
public class Account {

	// 存储账户余额
	private int balance;
	private long id;
	
	public Account(int balance, long id) {
		this.balance = balance;
		this.id = id;
	}
	
	// 存入一美元
	public void deposit() {
		synchronized(balance) {
			balance = balance + 1;
		}
	}
	
	// 取出一美元
	public void withdraw() {
		synchronized (balance) {
			balance = balance - 1;
		}
	}
	
	// 获得id
	public long getId() {
		return id;
	}
}
{% endhighlight %}

这个类里面有两个变量，相比之前增加了一个`id`的属性，这个属性不能修改。对于其余的两个操作，也只申请了`balance`的锁，但是这一就是线程安全的，因为对于`id`属性来说，它就相当于一个不可变的数据，不论怎么交错，都出来的值都是不变的。而对于另外两个操作，若是同时有两个线程 A、B 调用它们，那么后调用的那个线程 B 依旧会因为申请对`balance`的锁，而这个`balance`已经被先调用的线程 A 拥有，造成线程 B 被阻塞，效果和前面的例子类似。

但这 ADT 不像前面的例子那样，同时只能有一个操作进行，这个例子中`getId()`这个操作和其余两个操作是可以同时执行而不会产生竞争的。

此外，还可以在直接在方法的申明中加入`synchronized`关键字，下面这个例子效果和本小节的第一个例子效果类似：
{% highlight java %}
// 代表一个银行账户
public class Account {

	// 存储账户余额
	private int balance;
	private long id;
	
	public Account(int balance, long id) {
		this.balance = balance;
		this.id = id;
	}
	
	// 存入一美元
	public synchronized void deposit() {
			balance = balance + 1;
	}
	
	// 取出一美元
	public synchronized void withdraw() {
			balance = balance - 1;
	}
	
	// 获得id
	public long getId() {
		return id;
	}
}
{% endhighlight %}

**这里有一件事值得注意**，若是在静态方法申明中加入`synchronized`关键字，每当执行这个方法，就会申请这个类的锁（而不是这个类的实例）；

###### **3.2.2、共享多个数据**

从前面的例子可以看出来，只能申请对某个具体对象的锁，那么如果共享了多个数据，并且我们想要同时对它们进行操作怎么办？有两个方案：
* 一是将这些数据用一个类包装起来，对这些共享数据的操作只通过包装类，申请对包装类（的一个实例）的锁就可以锁住几个共享数据；
* 而是采用嵌套的结构；

第一个方式十分累赘，使用极其不灵活。举个例子，如果共享了三个数据结构 A、B、C，有时我只想同时修改 A、B，有时我只想同时修改 A、C，那么我就必须为这两种方式分别设计封装类。第二种方式就比较灵活了，看下面的例子：
{% highlight java %}
public class Test {

	public static void main(String[] args) {
		
		// data1 和 data2 是两个共享的数据
		Object data1 = null, data2 = null;
		
		synchronized (data1) {
			synchronized (data2) {
				// operate on data1 and data2...
			}
		}
	}
}
{% endhighlight %}

###### **3.2.3、锁住整个类**

前面讲到的例子，均只是锁住某个具体的实例。例如有`Account`的两个实例 A 和 B，那么 A 和 B 是完全独立的，锁住 A 时，依旧可以申请到对 B 的锁，反之亦然。

但是有时候，我们可能需要将整个类锁住。例如，我们现在有一个`Account`的列表作为共享数据，各个线程有个操作是比较各个账户余额的关系，那么在比较时，我们是期望所有的实例同时被锁住。否则，就会出现我们在比较 A 和 B 的关系后，A 的值被改变，那么当我们再继续比较 A 和 C 的关系后，来推测 B 和 C 的关系就会出现错误。

为了锁住整个类，有两种方式，一种是只提供静态的方法：
{% highlight java %}
//代表一个银行账户
class Account {

	// 存储账户余额
	private static int balance = 0;
	
	// 存入一美元
	public static synchronized void deposit() {
		balance = balance + 1;
	}
	
	// 取出一美元
	public static synchronized void withdraw() {
		balance = balance - 1;
	}
}
{% endhighlight %}
另一种方式是申请对某个类的锁，如下：
{% highlight java %}
public class Test {

	private static List<Account> accounts;
	public static void main(String[] args) {
		
		synchronized(Account.class) {
			// operate accounts
		}
	}
}

//代表一个银行账户
class Account {

	// 存储账户余额
	private int balance = 0;
	
	// 存入一美元
	public void deposit() {
		balance = balance + 1;
	}
	
	// 取出一美元
	public void withdraw() {
		balance = balance - 1;
	}
}
{% endhighlight %}

##### **3.3、关于 Synchronization 机制的使用建议**

那么是否应该在程序中大量使用 Synchronization 机制来保证程序是线程安全的呢？

**答案是否定的**。

最大的原因就是，Synchronization 机制严重降低多线程程序的性能。多线程本来是基于并行从而提高效率，而 Synchronization 机制使得程序近似串行执行，磨灭了多线程的优势。因此，Synchronization 机制应该：
* 在必要的时候再用，否则不用；
* 若一定要使用，则应该尽量减小其作用的范围；
* 避免出现死锁现象；